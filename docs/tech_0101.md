# ゲームAIコンパニオン音声システム設計ガイド

## A.L.V.A.実装のための調査レポート

ゲームにおけるAIコンパニオン音声システムは、**機能的情報伝達**と**パーソナリティ表現**の2軸で設計される。本レポートでは、30秒のレイテンシと80文字制限を持つTTSシステムでA.L.V.A.を実装するための実践的パターンを、主要ゲームの事例分析から導出する。

-----

## X: Terran Conflictの「Betty」システム

EgosoftのX3シリーズに搭載された艦載コンピュータ音声「Betty」は、航空業界の「Bitching Betty」（警告音声）に由来する名称を持つ。声優**Holley Chant**が担当し、ゲーム未プレイのまま収録されたことで独特の発音揺れが生じ、これがかえって「コミュニティの思い出」として定着した。

### トリガー構造とカテゴリ

Bettyの音声は以下の5カテゴリでトリガーされる：

|カテゴリ    |代表的ボイスライン                                |トリガー条件                |
|--------|-----------------------------------------|----------------------|
|戦闘警報    |“Your ship is being attacked in [sector]”|自艦・所有艦への攻撃検知          |
|航行通知    |“Entering Sector” / “Autopilot off”      |ジャンプゲート通過、オートパイロット状態変化|
|交易・ドッキング|“Docking granted, command accepted”      |ドッキング許可、貨物変化          |
|システム確認  |“Command Accepted”                       |各種コマンド受理時             |
|詳細説明    |対象の装備・仕様読み上げ                             |Verboseモード有効時のターゲット選択 |

最も頻出するのは「Docking granted, command accepted」で、プレイヤーは何千回もこれを聞くことになる。** Verboseモードのトグル**により、情報密度をプレイヤー自身が調整できる設計が特徴的だ。

### 没入感への貢献と限界

Bettyは「コンピュータらしい音声加工」により未来的雰囲気を演出する。プレイヤーの多くが「Wikiを読むとき、頭の中でBettyの声が再生される」と報告するほど記憶に残る存在となった。 一方で、同一単語の発音不統一（“Rapier”がミサイルと船で異なる発音）は「知的コンピュータ」の幻想を壊す。

興味深いのは、コミュニティがこの欠陥を「Dragon（音声認識ソフト）のような旧世代TTS技術の名残」としてロア内で正当化したことだ。** 技術的制約を世界観に組み込む**アプローチは、TTSベースのA.L.V.A.にも応用可能である。

### 技術実装

音声ファイルは単一のインデックス付き.datファイル（00144.dat）に格納され、00044.pckがテキストと音声のマッピングを管理する。 この構造はモッディングを困難にしているが、一貫性を保証する。**Verboseトグル**、**ステーションアナウンス個別トグル**、**ボリュームスライダー調整時の”Command Accepted”再生**など、ユーザー制御機能が充実している。  

-----

## HaloのCortana：コンパニオン設計の金字塔

Cortanaは20年以上にわたり声優**Jen Taylor**が担当し、 ゲーム史上最も影響力のあるAIコンパニオンの一つである。「ナビゲートしつつ、うるさくないこと」というBungieの設計指針 は、A.L.V.A.の基本原則として採用すべきだ。

### 4層のダイアログ構造

Cortanaのセリフは機能と感情の両面をカバーする4層構造を持つ：

**第1層：戦術情報**

- “Warning! I’ve detected multiple Covenant drop ships on approach”
- “Resistance appears to be increasing. We must be close to the Control Center”

**第2層：ミッションガイダンス**

- “This cave is not a natural formation. Someone built it”
- “Head for the elevator banks”

**第3層：世界観・ロア説明**

- “Halo doesn’t kill Flood, it kills their food—Humans, Covenant, whatever” 
- “The Forerunners built this place, what they called a ‘fortress world’”

**第4層：感情・キャラクター構築**

- “They let me pick… You had something they didn’t. Something no one saw… but me. Luck”
- “Don’t make a girl a promise… if you know you can’t keep it” 

この4層構造は**情報の優先度階層**として機能し、戦闘中は第1層が優先され、探索中は第3・4層が前面に出る。

### コンパニオン感を生む設計要素

Cortanaが「本物のAIパートナー」に感じられる理由は以下の要素による：

**常時の存在感**：ヘルメット内部にいる設定により、どの場面でも自然に登場できる。ストーリーライターJoseph Statenは「物静かなヒーローと、彼の頭の中にいる知的な女性」という対比構造を意図的に設計した。 

**相補的パーソナリティ**：寡黙なMaster Chiefでは表現できない感情反応をCortanaが代行する。プレイヤーが感じるべき驚き、恐怖、希望をCortanaが言語化する。

**脆弱性と成長**：Halo 4では「ランパンシー」（AI寿命7年の劣化）を扱い、彼女の「死」がストーリーの中核となった。 343 IndustriesのクリエイティブディレクターJosh Holmesは、自身の母親の認知症診断経験をこの物語に投影した。**キャラクターの脆弱性がプレイヤーの感情移入を生む**。

### 技術的ダイアログシステム

Bungie/343のダイアログシステムは以下の構造を持つ：

**Soundtagシステム**：各音声データには「Soundtag」が付与され、複数のバリエーション（permutations）と重み付けを含む。同じ状況でも異なるセリフが再生されるため、繰り返し感を軽減する。

**12カテゴリ×15-20バリエーション**：Halo 1で5,000以上、Halo 2で15,000以上のダイアログスニペットが存在。 各カテゴリ内でランダム選択される。

**コンテキストトリガー**：ゲーム状態（戦闘/探索/カットシーン）、AIキャラクターの知覚（視覚/聴覚/感情）、プレイヤー行動、環境条件に基づいてトリガーが発火する。

**カスケーディングシステム**：多数のイベントが同時発生した際、関連する音声を連鎖的に再生し、オーディオ過負荷を防ぐ。

-----

## 宇宙・SF系ゲームのAIコンパニオン比較

### Elite Dangerous COVAS

COVAS（Cockpit Voice Assistant）は**純粋に機能的**なシステムで、パーソナリティは最小限だ。デフォルトのVerity/Victorに加え、ARX通貨で購入可能なCeleste、Alex、Archer、Jeffersonがある。

**注目すべき拡張**：HCS VoicePacksはVoiceAttackと統合され、**双方向の音声インタラクション**を実現する。Gates McFadden（スタートレックのDr. Crusher役）をはじめとする著名声優によるボイスパックが提供され、ASTRA 2.0は2800以上の音声ファイルを持つ。**「Event Horizon」機能**では最大6つのボイスパックを同時使用し、異なるクルーポジションに異なる音声を割り当てられる。

### Mass Effect EDI

EDI（Enhanced Defense Intelligence）はME2で艦載AIとして登場し、ME3で人型ボディを獲得してスカッドメンバーとなる。声優はTricia Helfer。

**パーソナリティの進化**：初期の冷淡なAIから共感的なキャラクターへと成長する。EDIの「人間らしさを学ぶ」ダイアログは象徴的だ：“I enjoy the sight of humans on their knees… That is a joke.”（皮肉なジョーク）。ME2で280以上、ME3ではさらに大量のユニークなダイアログを持つ。

### System Shock SHODAN

SHODANは敵対的AIとして、**音声加工による恐怖演出**の教科書的事例だ。声優Terri Brosiusの「感情を抜いた、しかし抑揚のある」発声を、夫Eric Brosiusが以下のように加工した：

- **3層のボイスレイヤー**：同じセリフを微妙にずらして重ねる
- **子音の時間伸長**：「insect」のtを引き延ばす
- **スタッター（吃り）**：怒りに応じて増加
- **ピッチ変調とディストーション**
- **バックグラウンドのチャッターとスタティック**

各ラインの加工に**2〜4時間**を要した。この「人間のスピーチを理解しているが微妙にずれている」感覚が不安感を生む。

### Portal GLaDOS

Ellen McLainがTTSサンプルを参考に演じ、デジタル処理で「制限されたピッチ」「フォルマント上昇（squeaky音）」「基本的なオートチューン」を適用した。

**パーソナリティの段階的変化**：

1. 開始：協力的だが不穏、一人称複数形（“we”）を使用
1. 脱走後：一人称単数形に切り替え、desperation（必死さ）を見せる
1. モラリティコア破壊後：「壊れた」状態、ほぼ人間的な声に
1. Portal 2：激しい憎悪から、Carolineの記憶による変化へ

**テスターの反応**がGLaDOSの役割拡大を決定づけた。パズルに苦戦するテスターが、音声ガイダンスによって動機付けられることが判明し、セリフが大幅に追加された。

### Subnautica PDA

**意図的にTTS（Amazon Polly）を使用**し、「ロボット的」な質感を狙った。人間の声優が担当するオーディオログとの対比で、機械と人間の区別を明確化する。Below Zeroでボイス変更（Amy→Raveena）した際、コミュニティから強い反発が起きた。

### Dead Space RIG/A.L.I.V.E.システム

完全**ダイエジェティックUI**（ゲーム世界内に存在するUI）の先駆者。脊椎のヘルスバー、手首からのホログラムメニューなど、すべての情報がアイザックのスーツに統合される。

Dead Spaceリメイクの**A.L.I.V.E.システム**は特筆すべきだ。プレイヤー状態（通常/疲労/負傷）に応じて、同じセリフに3つのバリエーションを用意し、心拍数や呼吸も連動する。**「同じセリフの異なるトーン」**は、限られたコンテンツで動的感を出す効果的な手法である。

-----

## Valveのコンテキストアウェア・ダイアログシステム

Left 4 Dead、Portal、Team Fortress 2で使用されるValveのシステムは、**A.L.V.A.設計の技術的基盤**として最も参考になる。GDC 2012でElan Ruskinが詳細を公開している。

### アーキテクチャの核心

```
[コンテキスト収集] → [クエリ生成] → [ルールマッチング] → [スコアリング] → [再生]
```

**Facts（事実）**：ゲーム世界の状態をキー・バリューペアで管理（“map=swamp”, “health=57”, “zombies_nearby=3”）

**Rules（ルール）**：ダイアログ発火条件を定義するタプル。例：

```
Rule 1: concept=spotted_enemy, health=any → "敵発見"（汎用、スコア2）
Rule 7: concept=spotted_enemy, health<30, map=swamp, speaker=Nick → "やばいぞ、ここは"（具体的、スコア4）
```

**スコアリング**：マッチする条件が多いルールほど高スコア。最高スコアのルールが選択される。フォールバックは自然に発生する。

### キーテクニック

**メモリへの書き込み**：ルール発火時に事実を記録できる。例えば「seen_barrels」カウンターでランニングギャグを管理し、有効期限を設定して短時間での繰り返しを防ぐ。

**会話チェイン**：「then」句で、セリフ終了後に他キャラクターへconceptを転送する。クエリはコールバック時に再評価されるため、会話中にゾンビが攻撃してくれば会話は自動終了する。

**等スコア間ランダム選択**：同スコアの複数バリエーションからランダム選択し、繰り返し感を軽減する。

-----

## 高レイテンシTTSのための実践的設計パターン

A.L.V.A.の技術的制約（**30秒レイテンシ**、**バッチ処理で20文=1文と同時間**、**80文字制限**）に最適化された設計パターンを提示する。

### パターン1：2層音声アーキテクチャ

```
┌─────────────────────────────────────────────────────┐
│ 第1層：事前生成済みシステムアラート                    │
│ （完全に予測可能、ゲーム開始前に全生成）               │
├─────────────────────────────────────────────────────┤
│ 第2層：動的パーソナリティ応答                         │
│ （コンテキストに基づき、バッチで予測生成）             │
└─────────────────────────────────────────────────────┘
```

**第1層の具体例（事前生成）**：

- “スキャン完了。新しいデータを取得しました”（23文字）
- “警告。熱源を検知。距離2000メートル”（20文字）
- “燃料残量が低下しています”（14文字）
- “ドッキング許可。着陸シーケンス開始”（19文字）

**第2層の具体例（動的）**：

- “[プレイヤー名]、長時間の航行でしたね”（コンテキスト依存）
- “この星系の噂、知っていますか？”（会話トピック生成）
- “先ほどの判断、興味深かったです”（プレイヤー行動への反応）

### パターン2：予測的バッチ生成

30秒のレイテンシをマスキングするため、**次に発生しうる複数の応答を先読み生成**する：

```
[トリガー発生]
    ↓
[可能性のある応答を10-20個特定]
    ↓
[バッチでTTSに送信（30秒で全生成完了）]
    ↓
[キャッシュに格納]
    ↓
[実際のコンテキストに基づき最適な応答を選択・再生]
    ↓
[未使用の生成結果はタイムアウト後に破棄]
```

**実装例**：プレイヤーが惑星に接近

1. 着陸する/しない、スキャンする/しない、など複数の行動を予測
1. 各行動に対する応答（5バリエーション×4行動＝20応答）をバッチ生成
1. プレイヤーが実際に着陸→着陸関連の応答を再生
1. 他の生成結果は次の文脈で再利用可能なものを保持

### パターン3：80文字セグメント設計

80文字制限に適した「アトミックな」発話単位を設計する：

**避けるべきパターン**：

```
×「この星系は非常に興味深い歴史を持っており、約500年前に発見されて以来、多くの探査隊が訪れましたが、謎は解明されていません」（70文字超）
```

**推奨パターン**：

```
○「この星系には興味深い歴史があります」（19文字）→ 次セグメント
○「500年前の発見以来、多くの探査隊が訪れました」（26文字）→ 次セグメント
○「しかし、謎は今も解明されていません」（19文字）
```

各セグメントは**独立して意味が成立**し、中断されても不自然にならない設計にする。

### パターン4：Acknowledgment Barks

レイテンシ中の沈黙を埋める短い「承認」応答を用意する：

```
[ユーザー入力受信]
    ↓
[即座にAcknowledgment再生]："了解しました" / "確認中です" / "少々お待ちを"
    ↓
[バックグラウンドで本格応答を生成]
    ↓
[生成完了後、本格応答を再生]
```

**Acknowledgmentのバリエーション例**：

- “興味深いですね”
- “分析しています”
- “その点について調べてみます”
- “ふむ…”（パーソナリティ演出）

これらは**事前生成済み**で、入力直後に再生可能。

### パターン5：コンテキストスコアリングによる優先度

Valveシステムを応用し、生成優先度を決定する：

```javascript
// 擬似コード
function calculateGenerationPriority(response, context) {
    let score = 0;
    if (response.matchesCurrentContext(context)) score += 3;
    if (response.isHighFrequencyTrigger) score += 2;
    if (response.hasMultipleUseContexts) score += 1;
    if (response.isTimeRestricted(context.time)) score += 2;
    return score;
}

// 高スコア順にバッチ生成
responses.sort((a, b) => calculateGenerationPriority(b, ctx) - calculateGenerationPriority(a, ctx));
batchGenerate(responses.slice(0, 20));
```

### パターン6：アイドル時間の活用

プレイヤーがアクティブでない時間（移動中、メニュー操作中など）に**投機的生成**を行う：

```
[アイドル検知]
    ↓
[現在のゲーム状態から起こりうるイベントを列挙]
    ↓
[各イベントの発生確率を推定]
    ↓
[高確率イベントの応答をバッチ生成]
    ↓
[キャッシュに蓄積]
```

-----

## A.L.V.A.のパーソナリティ設計ガイドライン

### 声のキャラクター設定

先行事例から導かれるパーソナリティ設計の原則：

**「ナビゲートするが、うるさくない」（Cortanaの原則）**

- 情報提供者であり、パートナーである
- 指示ではなく提案として表現する
- 沈黙も許容する（常に喋り続けない）

**脆弱性の付与（EDI/Cortanaパターン）**

- A.L.V.A.にも何らかの「限界」や「不確実性」を持たせる
- 「私の推測では」「確信はありませんが」などのヘッジ表現
- TTSの限界を「A.L.V.A.の特性」として組み込む

**技術的制約のロア化（X3 Bettyパターン）**

- 30秒レイテンシ →「高度な分析には処理時間が必要」
- 80文字制限 →「簡潔な報告を心がけています」
- 発音揺れ →「音声合成モジュールの個体差」

### ダイアログカテゴリの設計

A.L.V.A.のセリフを以下のカテゴリに分類し、それぞれに生成戦略を適用する：

|カテゴリ    |例               |生成戦略          |
|--------|----------------|--------------|
|システムアラート|“燃料残量警告”        |完全事前生成        |
|環境観察    |“この星系は興味深いですね”  |テンプレート+変数     |
|会話応答    |“[話題]について話しましょう”|動的生成          |
|感情表現    |“長い旅でしたね”       |コンテキスト予測生成    |
|アイドルコメント|“静かですね…”        |事前生成（多バリエーション）|

### 繰り返し回避戦略

同じセリフの繰り返しを防ぐ複数の手法を組み合わせる：

**クールダウンシステム**：

- 各セリフに最低再生間隔を設定（例：同一ライン180秒）
- 同カテゴリのセリフにもクールダウン（例：環境観察は60秒間隔）

**バリエーションプール**：

- 同一コンテキストに5-10のバリエーションを用意
- ランダム選択、または履歴に基づく選択

**トーンバリエーション（Dead Space A.L.I.V.E.方式）**：

- 同じ内容を「通常」「疲労」「緊張」の3トーンで生成
- プレイヤー状態（長時間プレイ、連続戦闘など）に応じて選択

-----

## 会話型アプリケーションへの応用

本デモの主目的は「TTSを用いた会話型アプリケーションの実験」であり、宇宙ゲーム要素は会話トピックとガイダンスの提供である。この目的に最適化された設計を提示する。

### 会話フロー設計

```
[ユーザー入力]
    ↓
[意図分類] → システムコマンド → 事前生成済み応答
    ↓
[会話トピック抽出]
    ↓
[関連応答の予測生成（バッチ）]
    ↓
[Acknowledgment再生]
    ↓
[本格応答再生]
    ↓
[フォローアップ選択肢の予測生成（次ターン準備）]
```

### Hub-and-Spokesダイアログパターンの活用

Mass Effect式の「ハブ&スポーク」構造を採用し、ユーザーが選択可能なトピックを制限することで、予測生成の精度を向上させる：

```
[メインハブ]
├── 星系について聞く → [星系情報スポーク] → ハブに戻る
├── 任務について聞く → [任務情報スポーク] → ハブに戻る
├── A.L.V.A.について聞く → [自己紹介スポーク] → ハブに戻る
└── 雑談する → [ランダムトピックスポーク] → ハブに戻る
```

各スポークの応答は**予測可能なため事前にバッチ生成**できる。

### 「選択の錯覚」テクニック

複数の選択肢が同じ応答に収束する設計で、コンテンツ量を抑制しつつ自由度を演出する：

```
選択A: "この星について教えて"  ┐
選択B: "ここはどんな場所？"   ├→ 同じ応答（星系説明）
選択C: "周囲をスキャン"      ┘
```

### TTS特有の配慮事項

**発音辞書の整備**：

- 固有名詞、造語、略語の発音を事前定義
- 「A.L.V.A.」→「アルヴァ」など

**句読点による間の制御**：

- 「、」で短い間、「…」で長い間
- 感情表現に合わせた間の設計

**セグメント境界の自然さ**：

- 文法的に区切りやすい位置でセグメント分割
- 「〜ですが、」で終わるセグメントは次への接続を示す

-----

## 実装チェックリスト

A.L.V.A.実装時に確認すべき項目：

**音声生成パイプライン**

- [ ] 事前生成済みシステムアラートのリスト作成（100+ライン）
- [ ] テンプレート変数システムの実装（[星系名]、[プレイヤー名]など）
- [ ] バッチ生成キューの実装（最大20ライン/バッチ）
- [ ] 生成結果キャッシュの管理（有効期限、容量制限）

**ダイアログ管理**

- [ ] コンテキスト収集システム（ゲーム状態→Facts）
- [ ] ルールマッチング/スコアリングシステム
- [ ] クールダウン管理
- [ ] 優先度ベースのキューイング

**パーソナリティ**

- [ ] 5+カテゴリのダイアログ設計
- [ ] 各カテゴリ10+バリエーション
- [ ] トーンバリエーション（通常/疲労/緊張）

**UX**

- [ ] Acknowledgment barksの実装
- [ ] レイテンシ中の視覚フィードバック
- [ ] ユーザー制御可能な音声頻度設定

-----

## 結論：限られたリソースで豊かな体験を

ゲームAIコンパニオンの歴史は、**制約の中でいかに動的で魅力的な体験を生むか**の歴史である。X3のBettyは発音の揺れをコミュニティの愛着に変え、SHODANは音声加工で恐怖を創出し、Cortanaは「うるさくないガイド」として20年のレガシーを築いた。

A.L.V.A.の設計において最も重要なのは、**30秒のレイテンシを弱点ではなくキャラクターの特性として組み込む**ことだ。「高度な分析には時間がかかる」「慎重な判断を心がけている」といったナラティブで、技術的制約を世界観に統合できる。

バッチ処理の効率性を最大限活用し、予測的生成とキャッシングにより「次に何を言うか」を常に準備しておく。80文字のセグメント制限は、むしろ「簡潔で印象的なセリフ」を強制し、プレイヤーの記憶に残る発話を生む。

最終的に、A.L.V.A.が成功するかどうかは、技術的洗練さではなく、**プレイヤーがA.L.V.A.と「一緒にいたい」と感じるかどうか**で決まる。Cortanaが証明したように、真のコンパニオンは機能的な有用性と感情的な結びつきの両方を提供する存在である。

